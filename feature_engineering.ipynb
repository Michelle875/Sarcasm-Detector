{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a024aa3",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb3a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e93b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  ['state', 'slow', 'to', 'shut', 'down', 'weak'...      0\n",
      "1  ['drone', 'place', 'fresh', 'kill', 'on', 'ste...      1\n",
      "2  ['report', ':', 'majority', 'of', 'instance', ...      1\n",
      "3  ['sole', 'remain', 'lung', 'fill', 'with', 'ri...      1\n",
      "4      ['the', 'gop', \"'s\", 'stockholm', 'syndrome']      0\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "df_train = pd.read_csv('train_preprocessed.csv')\n",
    "df_valid = pd.read_csv('valid_preprocessed.csv')\n",
    "df_test = pd.read_csv('test_preprocessed.csv')\n",
    "\n",
    "print(df_train.head())\n",
    "# print(df_valid.head())\n",
    "# print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2a7af",
   "metadata": {},
   "source": [
    "## Tf-idf vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825dcbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19687)\t0.32426307516649433\n",
      "  (0, 19058)\t0.3992580875734305\n",
      "  (0, 20979)\t0.10798595426714692\n",
      "  (0, 18737)\t0.35965961259181517\n",
      "  (0, 6367)\t0.25803768539922634\n",
      "  (0, 22539)\t0.3959532813475212\n",
      "  (0, 20569)\t0.3175994757862391\n",
      "  (0, 6733)\t0.33285362959347153\n",
      "  (0, 16124)\t0.3992580875734305\n",
      "  (1, 6472)\t0.4257390088404465\n",
      "  (1, 15455)\t0.3966897313978762\n",
      "  (1, 8332)\t0.42908915986669816\n",
      "  (1, 11427)\t0.35063042205931494\n",
      "  (1, 14409)\t0.1757311845631749\n",
      "  (1, 19751)\t0.3914062605065885\n",
      "  (1, 14322)\t0.13429432618359566\n",
      "  (1, 22708)\t0.27847832528799155\n",
      "  (1, 10020)\t0.27323780791536617\n",
      "  (2, 20979)\t0.0770000428999051\n",
      "  (2, 14409)\t0.11562957690780681\n",
      "  (2, 14322)\t0.1767289756377389\n",
      "  (2, 17158)\t0.16578859502292492\n",
      "  (2, 12480)\t0.24121415038283242\n",
      "  (2, 10690)\t0.35115768604059283\n",
      "  (2, 15151)\t0.17922721469222705\n",
      "  :\t:\n",
      "  (8, 7472)\t0.370173061967635\n",
      "  (8, 15007)\t0.3839689469174912\n",
      "  (8, 11832)\t0.2887474388376089\n",
      "  (8, 14339)\t0.2887474388376089\n",
      "  (8, 5220)\t0.32923182711967436\n",
      "  (8, 13479)\t0.20220106107946978\n",
      "  (8, 20928)\t0.20738491930618927\n",
      "  (8, 12252)\t0.29209636512679976\n",
      "  (8, 4177)\t0.3598687795887432\n",
      "  (8, 17261)\t0.32923182711967436\n",
      "  (9, 14322)\t0.20303161113987828\n",
      "  (9, 13798)\t0.2053937046462446\n",
      "  (9, 9937)\t0.3331132000920421\n",
      "  (9, 20781)\t0.23297267438765834\n",
      "  (9, 22774)\t0.1914232678729363\n",
      "  (9, 1952)\t0.17598729310053474\n",
      "  (9, 7122)\t0.3490233717090392\n",
      "  (9, 16592)\t0.3299723793646631\n",
      "  (9, 3582)\t0.2934186769607898\n",
      "  (9, 11256)\t0.27266719751891066\n",
      "  (9, 8151)\t0.1211453302088989\n",
      "  (9, 8474)\t0.26068423189281587\n",
      "  (9, 22167)\t0.28213023055119096\n",
      "  (9, 15620)\t0.22641758714793886\n",
      "  (9, 416)\t0.28124841116357824\n"
     ]
    }
   ],
   "source": [
    "df_train_str = pd.read_csv('train.csv')['text']\n",
    "df_valid_str = pd.read_csv('valid.csv')['text']\n",
    "df_test_str  = pd.read_csv('test.csv')['text']\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "train_tfidf = vectorizer.fit_transform(df_train_str)\n",
    "valid_tfidf= vectorizer.transform(df_valid_str)\n",
    "test_tfidf  = vectorizer.transform(df_test_str)\n",
    "\n",
    "print(train_tfidf[:10, :]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd21fe63",
   "metadata": {},
   "source": [
    "## Static embeddings - hyperparameter: window size, GloVe vs word2vec\n",
    "word2vec context is interesting, but rare co-occurence can also indicate sarcasm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09b07e",
   "metadata": {},
   "source": [
    "## Sentiment frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ac5a5",
   "metadata": {},
   "source": [
    "## Sentence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef7130",
   "metadata": {},
   "source": [
    "## Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f1d0a",
   "metadata": {},
   "source": [
    "## first/last word frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed2593",
   "metadata": {},
   "source": [
    "## Bag of words (n-grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad2b11",
   "metadata": {},
   "source": [
    "## Parts of speech frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
